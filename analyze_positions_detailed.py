#!/usr/bin/env python3
"""
–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
–£—Ä–æ–≤–µ–Ω—å: Senior Developer
"""
import json
import csv
import math
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict, Counter
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
from data.database import get_database
from data.user_data import UserDataManager


class Priority(Enum):
    """–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"
    INFO = "INFO"


@dataclass
class HoldingTimeStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è"""
    count: int
    mean: float
    median: float
    std_dev: float
    min: float
    max: float
    q25: float  # –ü–µ—Ä–≤—ã–π –∫–≤–∞—Ä—Ç–∏–ª—å
    q75: float  # –¢—Ä–µ—Ç–∏–π –∫–≤–∞—Ä—Ç–∏–ª—å
    iqr: float  # –ú–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–∞—Ö
    cv: float  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
    mode_range: Tuple[float, float]  # –ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
    
    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class Recommendation:
    """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
    priority: Priority
    category: str
    issue: str
    current_value: Optional[float]
    target_value: Optional[float]
    recommendation: str
    expected_impact: str
    implementation_effort: str
    confidence: float  # 0.0 - 1.0
    
    def to_dict(self) -> Dict:
        return {
            **asdict(self),
            'priority': self.priority.value
        }


class PositionAnalyzer:
    """–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–∑–∏—Ü–∏–π"""
    
    def __init__(self, user_id: int = 8486449177):
        self.user_id = user_id
        self.db = get_database()
        self.user_data = UserDataManager()
        self.closed_trades = []
        self.open_trades = []
        self.holding_times_data = []
        
    def load_data(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î —Å fallback –Ω–∞ user_data"""
        try:
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ë–î
            self.closed_trades = self.db.get_closed_trades(self.user_id, limit=10000)
            
            # –ï—Å–ª–∏ –≤ –ë–î –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ user_data (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            if not self.closed_trades:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–µ–º–æ-–ø–æ–∑–∏—Ü–∏–∏ –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–∫—Ä—ã—Ç—ã–µ
                    all_trades = self.user_data.get_demo_positions(self.user_id)
                    self.closed_trades = [
                        t for t in all_trades 
                        if t.get('status') == 'closed' and t.get('close_price') is not None
                    ]
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    for trade in self.closed_trades:
                        if 'entry' in trade and 'entry_price' not in trade:
                            trade['entry_price'] = trade.get('entry', 0)
                        if 'close_price' not in trade:
                            trade['close_price'] = trade.get('close_price', 0)
                except Exception as fallback_err:
                    print(f"‚ö†Ô∏è Fallback –Ω–∞ user_data –Ω–µ —É–¥–∞–ª—Å—è: {fallback_err}")
            
            # –û—Ç–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏
            open_trades_raw = self.user_data.get_demo_positions(self.user_id)
            self.open_trades = [t for t in open_trades_raw if t.get('status') == 'open']
            
            print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(self.closed_trades)} –∑–∞–∫—Ä—ã—Ç—ã—Ö, {len(self.open_trades)} –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            import traceback
            traceback.print_exc()
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø—É—Å—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            self.closed_trades = []
            self.open_trades = []
    
    def parse_datetime(self, dt_value: Any) -> Optional[datetime]:
        """–ü–∞—Ä—Å–∏–Ω–≥ datetime –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        if not dt_value:
            return None
        
        try:
            if isinstance(dt_value, datetime):
                return dt_value
            
            if isinstance(dt_value, str):
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
                dt_value = dt_value.strip()
                
                # –ü—Ä–æ–±—É–µ–º ISO —Ñ–æ—Ä–º–∞—Ç (2024-01-22T10:30:00 –∏–ª–∏ 2024-01-22T10:30:00.123456)
                if 'T' in dt_value or ('-' in dt_value and ':' in dt_value):
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ ISO —Ñ–æ—Ä–º–∞—Ç–∞
                    dt_value = dt_value.replace('Z', '+00:00')
                    # –ï—Å–ª–∏ –Ω–µ—Ç timezone, –¥–æ–±–∞–≤–ª—è–µ–º
                    if '+' not in dt_value and dt_value.count(':') >= 2:
                        # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –±–µ–∑ timezone
                        try:
                            return datetime.fromisoformat(dt_value)
                        except:
                            # –ü—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å timezone
                            if dt_value.endswith('+00:00') or dt_value.endswith('-00:00'):
                                pass
                            else:
                                dt_value = dt_value + '+00:00'
                    return datetime.fromisoformat(dt_value)
                
                # –ü—Ä–æ–±—É–µ–º timestamp —Å—Ç—Ä–æ–∫—É
                try:
                    return datetime.fromtimestamp(float(dt_value))
                except (ValueError, OSError):
                    pass
                
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã
                formats = [
                    '%Y-%m-%d %H:%M:%S',
                    '%Y-%m-%d %H:%M:%S.%f',
                    '%Y-%m-%d',
                ]
                for fmt in formats:
                    try:
                        return datetime.strptime(dt_value, fmt)
                    except ValueError:
                        continue
            
            elif isinstance(dt_value, (int, float)):
                # Unix timestamp
                try:
                    return datetime.fromtimestamp(dt_value)
                except (OSError, ValueError):
                    # –ï—Å–ª–∏ timestamp —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
                    if dt_value > 1e10:
                        return datetime.fromtimestamp(dt_value / 1000)
            
            return None
        except Exception as e:
            # –¢–∏—Ö–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            return None
    
    def calculate_holding_times(self) -> List[Dict[str, Any]]:
        """–†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –ø–æ–∑–∏—Ü–∏–π —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        holding_times = []
        skipped_count = 0
        skipped_reasons = defaultdict(int)
        
        for trade in self.closed_trades:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∫–ª—é—á–µ–π –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏
            entry_time = trade.get('entry_time') or trade.get('timestamp') or trade.get('entry_timestamp')
            close_time = trade.get('close_time') or trade.get('close_timestamp')
            
            entry_dt = self.parse_datetime(entry_time)
            close_dt = self.parse_datetime(close_time)
            
            if not entry_dt:
                skipped_count += 1
                skipped_reasons['no_entry_time'] += 1
                continue
            
            if not close_dt:
                skipped_count += 1
                skipped_reasons['no_close_time'] += 1
                continue
            
            holding_minutes = (close_dt - entry_dt).total_seconds() / 60
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è
            if holding_minutes < 0:
                skipped_count += 1
                skipped_reasons['negative_time'] += 1
                continue
            
            if holding_minutes > 10000:  # –ë–æ–ª—å—à–µ ~7 –¥–Ω–µ–π - –≤–µ—Ä–æ—è—Ç–Ω–æ –æ—à–∏–±–∫–∞
                skipped_count += 1
                skipped_reasons['too_long'] += 1
                continue
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∫–ª—é—á–µ–π –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
            holding_times.append({
                'symbol': trade.get('symbol', 'UNKNOWN'),
                'direction': trade.get('direction', 'long'),
                'pnl': float(trade.get('pnl', trade.get('pnl', 0)) or 0),
                'minutes': holding_minutes,
                'hours': holding_minutes / 60,
                'entry_time': entry_dt,
                'close_time': close_dt,
                'close_reason': trade.get('close_reason', 'Unknown'),
                'entry_price': float(trade.get('entry_price', trade.get('entry', 0)) or 0),
                'close_price': float(trade.get('close_price', 0) or 0),
                'amount': float(trade.get('amount', 0) or 0),
                'probability': float(trade.get('probability', 0) or 0),
                'quality_score': float(trade.get('quality_score', 0) or 0)
            })
        
        if skipped_count > 0:
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {skipped_count} –ø–æ–∑–∏—Ü–∏–π: {dict(skipped_reasons)}")
        
        self.holding_times_data = holding_times
        return holding_times
    
    def calculate_advanced_stats(self, data: List[float]) -> HoldingTimeStats:
        """–†–∞—Å—á–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫"""
        if not data:
            return HoldingTimeStats(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, (0, 0))
        
        sorted_data = sorted(data)
        n = len(sorted_data)
        
        mean = statistics.mean(data)
        median = statistics.median(data)
        std_dev = statistics.stdev(data) if n > 1 else 0
        
        q25 = sorted_data[n // 4] if n >= 4 else sorted_data[0]
        q75 = sorted_data[3 * n // 4] if n >= 4 else sorted_data[-1]
        iqr = q75 - q25
        
        cv = (std_dev / mean * 100) if mean > 0 else 0  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (–º–æ–¥–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª)
        bins = 20
        bin_width = (max(data) - min(data)) / bins if max(data) > min(data) else 1
        histogram = Counter()
        for value in data:
            bin_idx = int((value - min(data)) / bin_width) if bin_width > 0 else 0
            bin_idx = min(bin_idx, bins - 1)
            histogram[bin_idx] += 1
        
        if histogram:
            mode_bin = histogram.most_common(1)[0][0]
            mode_start = min(data) + mode_bin * bin_width
            mode_end = mode_start + bin_width
            mode_range = (mode_start, mode_end)
        else:
            mode_range = (0, 0)
        
        return HoldingTimeStats(
            count=n,
            mean=mean,
            median=median,
            std_dev=std_dev,
            min=min(data),
            max=max(data),
            q25=q25,
            q75=q75,
            iqr=iqr,
            cv=cv,
            mode_range=mode_range
        )
    
    def analyze_time_distribution(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è"""
        if not self.holding_times_data:
            return {}
        
        minutes = [t['minutes'] for t in self.holding_times_data]
        stats = self.calculate_advanced_stats(minutes)
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        categories = {
            'scalping_ultra': [t for t in self.holding_times_data if t['minutes'] <= 2],
            'scalping_fast': [t for t in self.holding_times_data if 2 < t['minutes'] <= 5],
            'scalping_normal': [t for t in self.holding_times_data if 5 < t['minutes'] <= 10],
            'short_term': [t for t in self.holding_times_data if 10 < t['minutes'] <= 60],
            'medium_term': [t for t in self.holding_times_data if 60 < t['minutes'] <= 600],
            'long_term': [t for t in self.holding_times_data if t['minutes'] > 600]
        }
        
        category_stats = {}
        for cat_name, cat_trades in categories.items():
            if cat_trades:
                cat_pnl = sum(t['pnl'] for t in cat_trades)
                cat_wins = len([t for t in cat_trades if t['pnl'] > 0])
                cat_total = len(cat_trades)
                cat_wr = (cat_wins / cat_total * 100) if cat_total > 0 else 0
                
                category_stats[cat_name] = {
                    'count': cat_total,
                    'percentage': (cat_total / len(self.holding_times_data) * 100),
                    'total_pnl': cat_pnl,
                    'avg_pnl': cat_pnl / cat_total if cat_total > 0 else 0,
                    'win_rate': cat_wr,
                    'winning_trades': cat_wins,
                    'losing_trades': cat_total - cat_wins
                }
        
        return {
            'overall_stats': stats.to_dict(),
            'categories': category_stats,
            'total_trades': len(self.holding_times_data)
        }
    
    def analyze_profitability_by_time(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –≤—Ä–µ–º–µ–Ω–µ–º —É–¥–µ—Ä–∂–∞–Ω–∏—è –∏ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å—é"""
        if not self.holding_times_data:
            return {}
        
        profitable = [t for t in self.holding_times_data if t['pnl'] > 0]
        losing = [t for t in self.holding_times_data if t['pnl'] < 0]
        
        profitable_minutes = [t['minutes'] for t in profitable]
        losing_minutes = [t['minutes'] for t in losing]
        
        profitable_stats = self.calculate_advanced_stats(profitable_minutes) if profitable_minutes else None
        losing_stats = self.calculate_advanced_stats(losing_minutes) if losing_minutes else None
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∏ PnL
        if len(self.holding_times_data) > 1:
            minutes_list = [t['minutes'] for t in self.holding_times_data]
            pnl_list = [t['pnl'] for t in self.holding_times_data]
            
            # –ü—Ä–æ—Å—Ç–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞
            correlation = self._calculate_correlation(minutes_list, pnl_list)
        else:
            correlation = 0
        
        # –ê–Ω–∞–ª–∏–∑ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è
        optimal_time_ranges = self._find_optimal_time_ranges()
        
        return {
            'profitable_stats': profitable_stats.to_dict() if profitable_stats else None,
            'losing_stats': losing_stats.to_dict() if losing_stats else None,
            'correlation_time_pnl': correlation,
            'optimal_time_ranges': optimal_time_ranges,
            'profitable_count': len(profitable),
            'losing_count': len(losing)
        }
    
    def _calculate_correlation(self, x: List[float], y: List[float]) -> float:
        """–†–∞—Å—á–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞"""
        if len(x) != len(y) or len(x) < 2:
            return 0.0
        
        n = len(x)
        mean_x = sum(x) / n
        mean_y = sum(y) / n
        
        numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n))
        sum_sq_x = sum((x[i] - mean_x) ** 2 for i in range(n))
        sum_sq_y = sum((y[i] - mean_y) ** 2 for i in range(n))
        
        denominator = math.sqrt(sum_sq_x * sum_sq_y)
        
        if denominator == 0:
            return 0.0
        
        return numerator / denominator
    
    def _find_optimal_time_ranges(self) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è"""
        if not self.holding_times_data:
            return []
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –ø–æ 2 –º–∏–Ω—É—Ç—ã
        intervals = defaultdict(lambda: {'trades': [], 'pnl': 0, 'wins': 0})
        
        for trade in self.holding_times_data:
            interval = int(trade['minutes'] // 2) * 2  # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —á–µ—Ç–Ω–æ–≥–æ —á–∏—Å–ª–∞
            intervals[interval]['trades'].append(trade)
            intervals[interval]['pnl'] += trade['pnl']
            if trade['pnl'] > 0:
                intervals[interval]['wins'] += 1
        
        optimal_ranges = []
        for interval in sorted(intervals.keys())[:20]:  # –ü–µ—Ä–≤—ã–µ 20 –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ (–¥–æ 40 –º–∏–Ω—É—Ç)
            data = intervals[interval]
            count = len(data['trades'])
            if count >= 5:  # –ú–∏–Ω–∏–º—É–º 5 —Å–¥–µ–ª–æ–∫ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
                wr = (data['wins'] / count * 100) if count > 0 else 0
                avg_pnl = data['pnl'] / count if count > 0 else 0
                
                optimal_ranges.append({
                    'time_range': f"{interval}-{interval+2} –º–∏–Ω",
                    'count': count,
                    'win_rate': wr,
                    'avg_pnl': avg_pnl,
                    'total_pnl': data['pnl'],
                    'score': wr * 0.6 + (avg_pnl / 10) * 0.4  # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∫–æ—Ä
                })
        
        return sorted(optimal_ranges, key=lambda x: x['score'], reverse=True)[:5]
    
    def analyze_by_symbol(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–æ—Ä–≥–æ–≤—ã–º –ø–∞—Ä–∞–º"""
        if not self.holding_times_data:
            return {}
        
        symbol_stats = defaultdict(lambda: {
            'trades': [],
            'total_pnl': 0,
            'wins': 0,
            'total_minutes': 0
        })
        
        for trade in self.holding_times_data:
            symbol = trade['symbol']
            symbol_stats[symbol]['trades'].append(trade)
            symbol_stats[symbol]['total_pnl'] += trade['pnl']
            symbol_stats[symbol]['total_minutes'] += trade['minutes']
            if trade['pnl'] > 0:
                symbol_stats[symbol]['wins'] += 1
        
        result = {}
        for symbol, data in symbol_stats.items():
            count = len(data['trades'])
            if count > 0:
                result[symbol] = {
                    'count': count,
                    'win_rate': (data['wins'] / count * 100),
                    'total_pnl': data['total_pnl'],
                    'avg_pnl': data['total_pnl'] / count,
                    'avg_holding_minutes': data['total_minutes'] / count,
                    'scalping_percentage': len([t for t in data['trades'] if t['minutes'] <= 10]) / count * 100
                }
        
        return result
    
    def analyze_by_time_of_day(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫"""
        if not self.holding_times_data:
            return {}
        
        hour_stats = defaultdict(lambda: {'trades': [], 'pnl': 0, 'wins': 0, 'total_minutes': 0})
        
        for trade in self.holding_times_data:
            hour = trade['entry_time'].hour
            hour_stats[hour]['trades'].append(trade)
            hour_stats[hour]['pnl'] += trade['pnl']
            hour_stats[hour]['total_minutes'] += trade['minutes']
            if trade['pnl'] > 0:
                hour_stats[hour]['wins'] += 1
        
        result = {}
        for hour in range(24):
            if hour in hour_stats:
                data = hour_stats[hour]
                count = len(data['trades'])
                result[f"{hour:02d}:00"] = {
                    'count': count,
                    'win_rate': (data['wins'] / count * 100) if count > 0 else 0,
                    'avg_pnl': data['pnl'] / count if count > 0 else 0,
                    'total_pnl': data['pnl'],
                    'avg_holding_minutes': data['total_minutes'] / count if count > 0 else 0
                }
        
        return result
    
    def analyze_by_day_of_week(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏"""
        if not self.holding_times_data:
            return {}
        
        day_names = ['–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', '–í—Ç–æ—Ä–Ω–∏–∫', '–°—Ä–µ–¥–∞', '–ß–µ—Ç–≤–µ—Ä–≥', '–ü—è—Ç–Ω–∏—Ü–∞', '–°—É–±–±–æ—Ç–∞', '–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ']
        day_stats = defaultdict(lambda: {'trades': [], 'pnl': 0, 'wins': 0, 'total_minutes': 0})
        
        for trade in self.holding_times_data:
            weekday = trade['entry_time'].weekday()
            day_stats[weekday]['trades'].append(trade)
            day_stats[weekday]['pnl'] += trade['pnl']
            day_stats[weekday]['total_minutes'] += trade['minutes']
            if trade['pnl'] > 0:
                day_stats[weekday]['wins'] += 1
        
        result = {}
        for day_idx, day_name in enumerate(day_names):
            if day_idx in day_stats:
                data = day_stats[day_idx]
                count = len(data['trades'])
                result[day_name] = {
                    'count': count,
                    'win_rate': (data['wins'] / count * 100) if count > 0 else 0,
                    'avg_pnl': data['pnl'] / count if count > 0 else 0,
                    'total_pnl': data['pnl'],
                    'avg_holding_minutes': data['total_minutes'] / count if count > 0 else 0
                }
        
        return result
    
    def generate_recommendations(self) -> List[Recommendation]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å —Ä–∞—Å—á–µ—Ç–æ–º impact"""
        recommendations = []
        
        if not self.holding_times_data:
            return recommendations
        
        # 1. –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è
        minutes = [t['minutes'] for t in self.holding_times_data]
        stats = self.calculate_advanced_stats(minutes)
        time_dist = self.analyze_time_distribution()
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É –≤—Ä–µ–º–µ–Ω–∏
        if stats.mean > 10:
            scalping_pct = time_dist['categories'].get('scalping_normal', {}).get('percentage', 0)
            target_mean = 7.0
            potential_improvement = ((stats.mean - target_mean) / stats.mean * 100) if stats.mean > 0 else 0
            
            recommendations.append(Recommendation(
                priority=Priority.CRITICAL,
                category="–í—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è",
                issue=f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è {stats.mean:.1f} –º–∏–Ω –ø—Ä–µ–≤—ã—à–∞–µ—Ç —Ü–µ–ª–µ–≤–æ–µ –¥–ª—è —Å–∫–∞–ª—å–ø–∏–Ω–≥–∞ ({target_mean} –º–∏–Ω)",
                current_value=stats.mean,
                target_value=target_mean,
                recommendation=f"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —á–µ—Ä–µ–∑ {target_mean} –º–∏–Ω—É—Ç. –¢–µ–∫—É—â–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–∫–∞–ª—å–ø–∏–Ω–≥–∞: {scalping_pct:.1f}%",
                expected_impact=f"–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Å–∫–∞–ª—å–ø–∏–Ω–≥–∞ –¥–æ 80%+, —Å–Ω–∏–∂–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ {potential_improvement:.1f}%",
                implementation_effort="–ù–∏–∑–∫–∞—è (—É–∂–µ –≤–Ω–µ–¥—Ä–µ–Ω–æ)",
                confidence=0.95
            ))
        
        # 2. –ê–Ω–∞–ª–∏–∑ –¥–æ–ª–≥–∏—Ö –ø–æ–∑–∏—Ü–∏–π
        long_term_count = len([t for t in self.holding_times_data if t['minutes'] > 600])
        if long_term_count > 0:
            long_term_pct = (long_term_count / len(self.holding_times_data) * 100)
            recommendations.append(Recommendation(
                priority=Priority.CRITICAL,
                category="–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–∑–∏—Ü–∏–∏",
                issue=f"{long_term_count} –ø–æ–∑–∏—Ü–∏–π ({long_term_pct:.2f}%) —É–¥–µ—Ä–∂–∏–≤–∞–ª–∏—Å—å >10 —á–∞—Å–æ–≤",
                current_value=long_term_pct,
                target_value=0.0,
                recommendation="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —á–µ—Ä–µ–∑ 10 –º–∏–Ω—É—Ç —Å –Ω–∞–∏–≤—ã—Å—à–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º",
                expected_impact=f"–£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ {long_term_count} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤, —É–ª—É—á—à–µ–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã —Å–∫–∞–ª—å–ø–∏–Ω–≥–∞",
                implementation_effort="–ù–∏–∑–∫–∞—è (—É–∂–µ –≤–Ω–µ–¥—Ä–µ–Ω–æ)",
                confidence=1.0
            ))
        
        # 3. –ê–Ω–∞–ª–∏–∑ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
        profitability_analysis = self.analyze_profitability_by_time()
        optimal_ranges = profitability_analysis.get('optimal_time_ranges', [])
        
        if optimal_ranges:
            best_range = optimal_ranges[0]
            if best_range['win_rate'] > 60 and best_range['avg_pnl'] > 0:
                recommendations.append(Recommendation(
                    priority=Priority.HIGH,
                    category="–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏",
                    issue=f"–ù–∞–π–¥–µ–Ω–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è: {best_range['time_range']} (WR: {best_range['win_rate']:.1f}%, Avg PnL: {best_range['avg_pnl']:.2f})",
                    current_value=stats.mean,
                    target_value=float(best_range['time_range'].split('-')[0]) + 1,
                    recommendation=f"–°—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏–∏ –ø–æ–∑–∏—Ü–∏–π –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ {best_range['time_range']}",
                    expected_impact=f"–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ Win Rate –Ω–∞ {best_range['win_rate'] - (len([t for t in self.holding_times_data if t['pnl'] > 0]) / len(self.holding_times_data) * 100):.1f}%",
                    implementation_effort="–°—Ä–µ–¥–Ω—è—è (—Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞)",
                    confidence=0.75
                ))
        
        # 4. –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        if profitability_analysis.get('profitable_stats') and profitability_analysis.get('losing_stats'):
            prof_stats = profitability_analysis['profitable_stats']
            loss_stats = profitability_analysis['losing_stats']
            
            if prof_stats['mean'] < loss_stats['mean']:
                recommendations.append(Recommendation(
                    priority=Priority.MEDIUM,
                    category="–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —É–±—ã—Ç–∫–∞–º–∏",
                    issue=f"–ü—Ä–∏–±—ã–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –∑–∞–∫—Ä—ã–≤–∞—é—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ ({prof_stats['mean']:.1f} –º–∏–Ω) —á–µ–º —É–±—ã—Ç–æ—á–Ω—ã–µ ({loss_stats['mean']:.1f} –º–∏–Ω)",
                    current_value=loss_stats['mean'],
                    target_value=prof_stats['mean'] * 1.2,
                    recommendation=f"–î–æ–±–∞–≤–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —É–±—ã—Ç–æ—á–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π —á–µ—Ä–µ–∑ {prof_stats['mean'] * 1.2:.1f} –º–∏–Ω—É—Ç",
                    expected_impact=f"–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —É–±—ã—Ç–æ—á–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π –Ω–∞ {(loss_stats['mean'] - prof_stats['mean'] * 1.2) / loss_stats['mean'] * 100:.1f}%",
                    implementation_effort="–ù–∏–∑–∫–∞—è",
                    confidence=0.80
                ))
        
        # 5. –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–∞—Ä–∞–º
        symbol_analysis = self.analyze_by_symbol()
        problematic_symbols = [
            (sym, data) for sym, data in symbol_analysis.items()
            if data['avg_holding_minutes'] > 60 and data['win_rate'] < 50
        ]
        
        if problematic_symbols:
            worst = sorted(problematic_symbols, key=lambda x: x[1]['avg_holding_minutes'], reverse=True)[0]
            recommendations.append(Recommendation(
                priority=Priority.MEDIUM,
                category="–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ä—ã",
                issue=f"{worst[0]}: —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è {worst[1]['avg_holding_minutes']:.1f} –º–∏–Ω, WR {worst[1]['win_rate']:.1f}%",
                current_value=worst[1]['avg_holding_minutes'],
                target_value=10.0,
                recommendation=f"–î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è {worst[0]} –∏–ª–∏ –∏—Å–∫–ª—é—á–∏—Ç—å –∏–∑ —Ç–æ—Ä–≥–æ–≤–ª–∏",
                expected_impact=f"–£–ª—É—á—à–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø–∞—Ä",
                implementation_effort="–°—Ä–µ–¥–Ω—è—è",
                confidence=0.70
            ))
        
        # 6. –ê–Ω–∞–ª–∏–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –≤–∞—Ä–∏–∞—Ü–∏–∏
        if stats.cv > 100:
            recommendations.append(Recommendation(
                priority=Priority.MEDIUM,
                category="–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å",
                issue=f"–í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è (CV: {stats.cv:.1f}%)",
                current_value=stats.cv,
                target_value=50.0,
                recommendation="–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏–∫—É –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–π, –¥–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä–æ–≥–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ª–∏–º–∏—Ç—ã",
                expected_impact=f"–°–Ω–∏–∂–µ–Ω–∏–µ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ {(stats.cv - 50) / stats.cv * 100:.1f}%, –ø–æ–≤—ã—à–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏",
                implementation_effort="–°—Ä–µ–¥–Ω—è—è",
                confidence=0.65
            ))
        
        # 7. –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π
        anomalies = self.detect_anomalies()
        if anomalies.get('time_outliers', {}).get('count', 0) > 10:
            outliers_count = anomalies['time_outliers']['count']
            outliers_pct = (outliers_count / len(self.holding_times_data) * 100) if self.holding_times_data else 0
            recommendations.append(Recommendation(
                priority=Priority.HIGH,
                category="–ê–Ω–æ–º–∞–ª–∏–∏",
                issue=f"{outliers_count} –ø–æ–∑–∏—Ü–∏–π ({outliers_pct:.1f}%) —è–≤–ª—è—é—Ç—Å—è –≤—ã–±—Ä–æ—Å–∞–º–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è",
                current_value=outliers_pct,
                target_value=2.0,  # –ù–µ –±–æ–ª–µ–µ 2% –≤—ã–±—Ä–æ—Å–æ–≤
                recommendation="–£—Å–∏–ª–∏—Ç—å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ, –¥–æ–±–∞–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–Ω–æ–º–∞–ª–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏",
                expected_impact=f"–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ —Å {outliers_pct:.1f}% –¥–æ <2%, —É–ª—É—á—à–µ–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã —Å–∫–∞–ª—å–ø–∏–Ω–≥–∞",
                implementation_effort="–°—Ä–µ–¥–Ω—è—è",
                confidence=0.85
            ))
        
        # 8. –ê–Ω–∞–ª–∏–∑ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫
        time_of_day = self.analyze_by_time_of_day()
        if time_of_day:
            best_hours = sorted(
                [(h, d) for h, d in time_of_day.items() if d['count'] >= 10],
                key=lambda x: x[1]['win_rate'] * 0.6 + (x[1]['avg_pnl'] / 100) * 0.4,
                reverse=True
            )[:3]
            
            worst_hours = sorted(
                [(h, d) for h, d in time_of_day.items() if d['count'] >= 10],
                key=lambda x: x[1]['win_rate'] * 0.6 + (x[1]['avg_pnl'] / 100) * 0.4
            )[:3]
            
            if worst_hours and best_hours:
                worst = worst_hours[0]
                best = best_hours[0]
                wr_diff = best[1]['win_rate'] - worst[1]['win_rate']
                if wr_diff > 15:
                    recommendations.append(Recommendation(
                        priority=Priority.LOW,
                        category="–í—Ä–µ–º—è —Å—É—Ç–æ–∫",
                        issue=f"–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {worst[0]} (WR: {worst[1]['win_rate']:.1f}%) vs {best[0]} (WR: {best[1]['win_rate']:.1f}%)",
                        current_value=worst[1]['win_rate'],
                        target_value=best[1]['win_rate'],
                        recommendation=f"–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Å–Ω–∏–∂–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤ {worst[0]} –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤. –£–≤–µ–ª–∏—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ {best[0]}",
                        expected_impact=f"–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ Win Rate –Ω–∞ {wr_diff:.1f}% –≤ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —á–∞—Å—ã",
                        implementation_effort="–ù–∏–∑–∫–∞—è",
                        confidence=0.60
                    ))
        
        # 9. –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
        day_of_week = self.analyze_by_day_of_week()
        if day_of_week:
            days_with_data = [(d, data) for d, data in day_of_week.items() if data['count'] >= 20]
            if len(days_with_data) >= 3:
                best_day = max(days_with_data, key=lambda x: x[1]['win_rate'])
                worst_day = min(days_with_data, key=lambda x: x[1]['win_rate'])
                
                if best_day[1]['win_rate'] - worst_day[1]['win_rate'] > 20:
                    recommendations.append(Recommendation(
                        priority=Priority.LOW,
                        category="–î–Ω–∏ –Ω–µ–¥–µ–ª–∏",
                        issue=f"–†–∞–∑–Ω–∏—Ü–∞ –≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {worst_day[0]} (WR: {worst_day[1]['win_rate']:.1f}%) vs {best_day[0]} (WR: {best_day[1]['win_rate']:.1f}%)",
                        current_value=worst_day[1]['win_rate'],
                        target_value=best_day[1]['win_rate'],
                        recommendation=f"–°–Ω–∏–∑–∏—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ {worst_day[0]}, —É–≤–µ–ª–∏—á–∏—Ç—å –≤ {best_day[0]}",
                        expected_impact=f"–£–ª—É—á—à–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ Win Rate –Ω–∞ {(best_day[1]['win_rate'] - worst_day[1]['win_rate']) / 2:.1f}%",
                        implementation_effort="–ù–∏–∑–∫–∞—è",
                        confidence=0.55
                    ))
        
        # 10. –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å–∏–≥–Ω–∞–ª–∞
        if any(t.get('probability', 0) > 0 for t in self.holding_times_data):
            prob_ranges = {
                'high': [t for t in self.holding_times_data if t.get('probability', 0) >= 60],
                'medium': [t for t in self.holding_times_data if 40 <= t.get('probability', 0) < 60],
                'low': [t for t in self.holding_times_data if 0 < t.get('probability', 0) < 40]
            }
            
            for prob_level, trades in prob_ranges.items():
                if len(trades) >= 20:
                    wins = len([t for t in trades if t['pnl'] > 0])
                    wr = (wins / len(trades) * 100) if trades else 0
                    avg_pnl = sum(t['pnl'] for t in trades) / len(trades) if trades else 0
                    
                    if prob_level == 'low' and wr < 40:
                        recommendations.append(Recommendation(
                            priority=Priority.MEDIUM,
                            category="–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤",
                            issue=f"–ù–∏–∑–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤ (<40%) –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç WR {wr:.1f}% –∏ Avg PnL {avg_pnl:.2f} USDT",
                            current_value=wr,
                            target_value=50.0,
                            recommendation=f"–ò—Å–∫–ª—é—á–∏—Ç—å —Å–∏–≥–Ω–∞–ª—ã —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é <40% –∏–∑ —Ç–æ—Ä–≥–æ–≤–ª–∏",
                            expected_impact=f"–£–ª—É—á—à–µ–Ω–∏–µ Win Rate –Ω–∞ {50 - wr:.1f}%, —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ —É–±—ã—Ç–æ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫",
                            implementation_effort="–ù–∏–∑–∫–∞—è",
                            confidence=0.75
                        ))
                        break
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        priority_order_list = [Priority.CRITICAL, Priority.HIGH, Priority.MEDIUM, Priority.LOW, Priority.INFO]
        recommendations.sort(key=lambda r: (
            priority_order_list.index(r.priority),
            -r.confidence
        ))
        
        return recommendations
    
    def _export_to_csv(self, filepath: str) -> None:
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ CSV"""
        if not self.holding_times_data:
            return
        
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=[
                'symbol', 'direction', 'entry_time', 'close_time', 'holding_minutes', 
                'holding_hours', 'entry_price', 'close_price', 'pnl', 'close_reason',
                'probability', 'quality_score'
            ])
            writer.writeheader()
            
            for trade in self.holding_times_data:
                writer.writerow({
                    'symbol': trade['symbol'],
                    'direction': trade['direction'],
                    'entry_time': trade['entry_time'].isoformat() if isinstance(trade['entry_time'], datetime) else str(trade['entry_time']),
                    'close_time': trade['close_time'].isoformat() if isinstance(trade['close_time'], datetime) else str(trade['close_time']),
                    'holding_minutes': round(trade['minutes'], 2),
                    'holding_hours': round(trade['hours'], 2),
                    'entry_price': trade['entry_price'],
                    'close_price': trade['close_price'],
                    'pnl': round(trade['pnl'], 2),
                    'close_reason': trade['close_reason'],
                    'probability': trade['probability'],
                    'quality_score': trade['quality_score']
                })
    
    def _export_to_markdown(self, report: Dict[str, Any], filepath: str) -> None:
        """–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –≤ Markdown —Ñ–æ—Ä–º–∞—Ç"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("# üìä –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π\n\n")
            f.write(f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞**: {report['analysis_date']}\n")
            f.write(f"**User ID**: {report['user_id']}\n\n")
            
            # –°–≤–æ–¥–∫–∞
            f.write("## üìà –°–≤–æ–¥–∫–∞\n\n")
            f.write(f"- –ó–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π: **{report['summary']['total_closed']}**\n")
            f.write(f"- –û—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π: **{report['summary']['total_open']}**\n\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
            if report.get('time_distribution'):
                f.write("## ‚è±Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è\n\n")
                stats = report['time_distribution']['overall_stats']
                f.write(f"- –°—Ä–µ–¥–Ω–µ–µ: **{stats['mean']:.2f}** –º–∏–Ω—É—Ç\n")
                f.write(f"- –ú–µ–¥–∏–∞–Ω–∞: **{stats['median']:.2f}** –º–∏–Ω—É—Ç\n")
                f.write(f"- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: **{stats['std_dev']:.2f}** –º–∏–Ω—É—Ç\n")
                f.write(f"- –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏: **{stats['cv']:.2f}%**\n\n")
                
                f.write("### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n\n")
                f.write("| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ | % | Win Rate | Avg PnL |\n")
                f.write("|-----------|------------|---|----------|----------|\n")
                
                categories = report['time_distribution']['categories']
                for cat_name, cat_data in categories.items():
                    f.write(f"| {cat_name} | {cat_data['count']} | {cat_data['percentage']:.1f}% | "
                           f"{cat_data['win_rate']:.1f}% | {cat_data['avg_pnl']:.2f} USDT |\n")
                f.write("\n")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if report.get('recommendations'):
                f.write("## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n")
                for rec in report['recommendations']:
                    priority_emoji = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}.get(rec['priority'], '‚ö™')
                    f.write(f"### {priority_emoji} [{rec['priority']}] {rec['category']}\n\n")
                    f.write(f"**–ü—Ä–æ–±–ª–µ–º–∞**: {rec['issue']}\n\n")
                    if rec.get('current_value') and rec.get('target_value'):
                        f.write(f"**–¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ**: {rec['current_value']:.2f}\n")
                        f.write(f"**–¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ**: {rec['target_value']:.2f}\n\n")
                    f.write(f"**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: {rec['recommendation']}\n\n")
                    f.write(f"**–û–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç**: {rec['expected_impact']}\n\n")
                    f.write(f"**–°–ª–æ–∂–Ω–æ—Å—Ç—å**: {rec['implementation_effort']} | **–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å**: {rec['confidence']*100:.0f}%\n\n")
                    f.write("---\n\n")
    
    def detect_anomalies(self) -> Dict[str, Any]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö"""
        if not self.holding_times_data:
            return {}
        
        minutes = [t['minutes'] for t in self.holding_times_data]
        stats = self.calculate_advanced_stats(minutes)
        
        # –ê–Ω–æ–º–∞–ª–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–≤—ã–±—Ä–æ—Å—ã)
        outliers = []
        for trade in self.holding_times_data:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª–æ 1.5 * IQR
            if trade['minutes'] > stats.q75 + 1.5 * stats.iqr:
                outliers.append(trade)
        
        # –ê–Ω–æ–º–∞–ª–∏–∏ –ø–æ PnL (–Ω–µ–æ–±—ã—á–Ω–æ –±–æ–ª—å—à–∏–µ –ø—Ä–∏–±—ã–ª–∏/—É–±—ã—Ç–∫–∏)
        pnl_values = [t['pnl'] for t in self.holding_times_data]
        if pnl_values:
            pnl_mean = statistics.mean(pnl_values)
            pnl_std = statistics.stdev(pnl_values) if len(pnl_values) > 1 else 0
            
            extreme_pnl = []
            for trade in self.holding_times_data:
                if pnl_std > 0:
                    z_score = abs((trade['pnl'] - pnl_mean) / pnl_std)
                    if z_score > 3:  # –ë–æ–ª–µ–µ 3 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
                        extreme_pnl.append({
                            **trade,
                            'z_score': z_score
                        })
        
        return {
            'time_outliers': {
                'count': len(outliers),
                'threshold_minutes': stats.q75 + 1.5 * stats.iqr,
                'examples': sorted(outliers, key=lambda x: x['minutes'], reverse=True)[:10]
            },
            'extreme_pnl': {
                'count': len(extreme_pnl),
                'examples': sorted(extreme_pnl, key=lambda x: abs(x['pnl']), reverse=True)[:10]
            }
        }
    
    def analyze_open_positions(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π"""
        if not self.open_trades:
            return {'count': 0, 'positions': []}
        
        current_time = datetime.now()
        positions = []
        
        for trade in self.open_trades:
            entry_dt = self.parse_datetime(trade.get('entry_time'))
            if not entry_dt:
                continue
            
            holding_minutes = (current_time - entry_dt).total_seconds() / 60
            
            positions.append({
                'symbol': trade.get('symbol'),
                'direction': trade.get('direction'),
                'entry': trade.get('entry', 0),
                'minutes': holding_minutes,
                'hours': holding_minutes / 60,
                'entry_time': entry_dt.isoformat(),
                'status': 'CRITICAL' if holding_minutes > 600 else 'WARNING' if holding_minutes > 60 else 'NORMAL'
            })
        
        return {
            'count': len(positions),
            'positions': sorted(positions, key=lambda x: x['minutes'], reverse=True),
            'avg_minutes': sum(p['minutes'] for p in positions) / len(positions) if positions else 0,
            'critical_count': len([p for p in positions if p['minutes'] > 600])
        }
    
    def generate_report(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        self.load_data()
        holding_times = self.calculate_holding_times()
        
        report = {
            'analysis_date': datetime.now().isoformat(),
            'user_id': self.user_id,
            'summary': {
                'total_closed': len(holding_times),
                'total_open': len(self.open_trades)
            },
            'time_distribution': self.analyze_time_distribution(),
            'profitability_analysis': self.analyze_profitability_by_time(),
            'symbol_analysis': self.analyze_by_symbol(),
            'time_of_day_analysis': self.analyze_by_time_of_day(),
            'day_of_week_analysis': self.analyze_by_day_of_week(),
            'open_positions': self.analyze_open_positions(),
            'anomalies': self.detect_anomalies(),
            'recommendations': [r.to_dict() for r in self.generate_recommendations()]
        }
        
        return report
    
    def print_report(self, report: Dict[str, Any]) -> None:
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –≤ –∫–æ–Ω—Å–æ–ª—å"""
        print("=" * 100)
        print("üìä –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–û–†–ì–û–í–´–• –ü–û–ó–ò–¶–ò–ô")
        print("=" * 100)
        
        # –°–≤–æ–¥–∫–∞
        print(f"\nüìà –°–í–û–î–ö–ê:")
        print(f"  –ó–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π: {report['summary']['total_closed']}")
        print(f"  –û—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π: {report['summary']['total_open']}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
        if report['time_distribution']:
            stats = report['time_distribution']['overall_stats']
            print(f"\n‚è±Ô∏è  –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–†–ï–ú–ï–ù–ò –£–î–ï–†–ñ–ê–ù–ò–Ø:")
            print(f"  –°—Ä–µ–¥–Ω–µ–µ: {stats['mean']:.2f} –º–∏–Ω (–º–µ–¥–∏–∞–Ω–∞: {stats['median']:.2f} –º–∏–Ω)")
            print(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {stats['std_dev']:.2f} –º–∏–Ω")
            print(f"  –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏: {stats['cv']:.2f}%")
            print(f"  –ö–≤–∞—Ä—Ç–∏–ª–∏: Q1={stats['q25']:.1f} –º–∏–Ω, Q3={stats['q75']:.1f} –º–∏–Ω, IQR={stats['iqr']:.1f} –º–∏–Ω")
            print(f"  –ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: {stats['mode_range'][0]:.1f}-{stats['mode_range'][1]:.1f} –º–∏–Ω")
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            print(f"\n  üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
            categories = report['time_distribution']['categories']
            for cat_name, cat_data in categories.items():
                emoji = "‚úÖ" if "scalping" in cat_name else "‚ö†Ô∏è" if "short" in cat_name else "‚ùå"
                print(f"    {emoji} {cat_name:20s}: {cat_data['count']:4d} ({cat_data['percentage']:5.1f}%) | "
                      f"WR: {cat_data['win_rate']:5.1f}% | Avg PnL: {cat_data['avg_pnl']:8.2f} USDT")
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏
        if report['profitability_analysis']:
            prof_analysis = report['profitability_analysis']
            print(f"\nüí∞ –ê–ù–ê–õ–ò–ó –ü–†–ò–ë–´–õ–¨–ù–û–°–¢–ò:")
            if prof_analysis.get('correlation_time_pnl'):
                corr = prof_analysis['correlation_time_pnl']
                corr_interpretation = "—Å–∏–ª—å–Ω–∞—è" if abs(corr) > 0.7 else "—É–º–µ—Ä–µ–Ω–Ω–∞—è" if abs(corr) > 0.4 else "—Å–ª–∞–±–∞—è"
                direction = "–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è" if corr > 0 else "–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è"
                print(f"  –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –≤—Ä–µ–º—è-PnL: {corr:.3f} ({corr_interpretation}, {direction})")
            
            if prof_analysis.get('optimal_time_ranges'):
                print(f"\n  üéØ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –≤—Ä–µ–º–µ–Ω–∏:")
                for i, opt_range in enumerate(prof_analysis['optimal_time_ranges'][:3], 1):
                    print(f"    {i}. {opt_range['time_range']:15s} | "
                          f"WR: {opt_range['win_rate']:5.1f}% | "
                          f"Avg PnL: {opt_range['avg_pnl']:8.2f} USDT | "
                          f"–°–¥–µ–ª–æ–∫: {opt_range['count']}")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
        if report.get('day_of_week_analysis'):
            print(f"\nüìÖ –ê–ù–ê–õ–ò–ó –ü–û –î–ù–Ø–ú –ù–ï–î–ï–õ–ò:")
            day_analysis = report['day_of_week_analysis']
            for day_name, day_data in sorted(day_analysis.items(), key=lambda x: x[1]['win_rate'], reverse=True):
                if day_data['count'] >= 10:  # –ú–∏–Ω–∏–º—É–º 10 —Å–¥–µ–ª–æ–∫ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    print(f"  {day_name:15s} | –°–¥–µ–ª–æ–∫: {day_data['count']:3d} | "
                          f"WR: {day_data['win_rate']:5.1f}% | "
                          f"Avg PnL: {day_data['avg_pnl']:8.2f} USDT | "
                          f"–°—Ä. –≤—Ä–µ–º—è: {day_data['avg_holding_minutes']:5.1f} –º–∏–Ω")
        
        # –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π
        if report.get('anomalies'):
            anomalies = report['anomalies']
            print(f"\nüîç –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –ê–ù–û–ú–ê–õ–ò–ô:")
            
            if anomalies.get('time_outliers', {}).get('count', 0) > 0:
                outliers = anomalies['time_outliers']
                print(f"  ‚ö†Ô∏è –í—ã–±—Ä–æ—Å—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏: {outliers['count']} –ø–æ–∑–∏—Ü–∏–π > {outliers['threshold_minutes']:.1f} –º–∏–Ω")
                if outliers.get('examples'):
                    print(f"    –¢–æ–ø-3 –ø—Ä–∏–º–µ—Ä–∞:")
                    for ex in outliers['examples'][:3]:
                        print(f"      {ex['symbol']:20s} | {ex['hours']:6.1f} —á–∞—Å–æ–≤ | PnL: {ex['pnl']:8.2f} USDT")
            
            if anomalies.get('extreme_pnl', {}).get('count', 0) > 0:
                extreme = anomalies['extreme_pnl']
                print(f"  üí∞ –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ PnL: {extreme['count']} –ø–æ–∑–∏—Ü–∏–π (Z-score > 3)")
                if extreme.get('examples'):
                    print(f"    –¢–æ–ø-3 –ø—Ä–∏–º–µ—Ä–∞:")
                    for ex in extreme['examples'][:3]:
                        print(f"      {ex['symbol']:20s} | PnL: {ex['pnl']:8.2f} USDT | Z-score: {ex.get('z_score', 0):.2f}")
        
        # –û—Ç–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏
        if report['open_positions']['count'] > 0:
            print(f"\nüî¥ –û–¢–ö–†–´–¢–´–ï –ü–û–ó–ò–¶–ò–ò ({report['open_positions']['count']}):")
            for pos in report['open_positions']['positions'][:10]:
                status_emoji = "üî¥" if pos['status'] == 'CRITICAL' else "üü°" if pos['status'] == 'WARNING' else "üü¢"
                print(f"  {status_emoji} {pos['symbol']:20s} | {pos['hours']:6.1f} —á–∞—Å–æ–≤ | {pos['direction'].upper()}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if report['recommendations']:
            print(f"\n" + "=" * 100)
            print(f"üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò (–ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø–æ impact):")
            print("=" * 100)
            
            priority_order = [Priority.CRITICAL, Priority.HIGH, Priority.MEDIUM, Priority.LOW, Priority.INFO]
            priority_emoji = {
                Priority.CRITICAL: 'üî¥',
                Priority.HIGH: 'üü†',
                Priority.MEDIUM: 'üü°',
                Priority.LOW: 'üü¢',
                Priority.INFO: '‚ö™'
            }
            
            for priority in priority_order:
                recs = [r for r in report['recommendations'] if r['priority'] == priority.value]
                if recs:
                    print(f"\n{priority_emoji[priority]} [{priority.value}]")
                    for rec in recs:
                        print(f"  üìå {rec['category']}: {rec['issue']}")
                        if rec.get('current_value') and rec.get('target_value'):
                            print(f"     –¢–µ–∫—É—â–µ–µ: {rec['current_value']:.2f} ‚Üí –¶–µ–ª–µ–≤–æ–µ: {rec['target_value']:.2f}")
                        print(f"     üí° {rec['recommendation']}")
                        print(f"     üìà –û–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç: {rec['expected_impact']}")
                        print(f"     ‚öôÔ∏è  –°–ª–æ–∂–Ω–æ—Å—Ç—å: {rec['implementation_effort']} | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {rec['confidence']*100:.0f}%")
                        print()


def analyze_positions_detailed(user_id: int = 8486449177):
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        analyzer = PositionAnalyzer(user_id)
        report = analyzer.generate_report()
        analyzer.print_report(report)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON –æ—Ç—á–µ—Ç
        json_path = f'positions_analysis_report_{timestamp}.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        print(f"\n‚úÖ JSON –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {json_path}")
        
        # CSV —ç–∫—Å–ø–æ—Ä—Ç –ø–æ–∑–∏—Ü–∏–π
        if analyzer.holding_times_data:
            csv_path = f'positions_detailed_{timestamp}.csv'
            analyzer._export_to_csv(csv_path)
            print(f"‚úÖ CSV —ç–∫—Å–ø–æ—Ä—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {csv_path}")
        
        # Markdown –æ—Ç—á–µ—Ç
        md_path = f'positions_analysis_report_{timestamp}.md'
        analyzer._export_to_markdown(report, md_path)
        print(f"‚úÖ Markdown –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {md_path}")
        
        print("=" * 100)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    analyze_positions_detailed()
